Theme: casa notes
Palette: Purple
Size: Wide
Title: Data Structures
Author: Jon Reades

---
Layout: Title
# From DoLs to Data Structures
---
## Another Look
```
my_cities = {
  'London': [[51.5072, 0.1275], +0], 
  'New York': [[40.7127, 74.0059], -5], 
  'Tokyo': [[35.6833, 139.6833], +8]
}
```
So:
```
print(my_cities['London'][0])
> [51.5072, 0.1275]
```
---
## Compare...

```
my_cities = [
  {name: 'London', loc: [51.5072, 0.1275], tz: +0}, 
  {name: 'New York', loc: [40.7127, 74.0059], tz: -5}, 
  {name: 'Tokyo', loc: [35.6833, 139.6833], tz: +8}
]
```


```
my_cities = {
  'London': {'loc': [51.5072, 0.1275], 'tz': +0}, 
  'New York': {'loc': [40.7127, 74.0059], 'tz': -5}, 
  'Tokyo': {'loc': [35.6833, 139.6833], 'tz': +8}
}
```

![Quick Quiz](mi_question_answer)  Is either of these the **right way** to store data?

---
### Implications

> So we can mix and match dictionaries and lists in whatever way we need to store... 'data'. The question is then: what's the **right** way to store our data?

^ **Answer**: the way that makes the most **sense** to a human while *also* being the most **robust** for coding.
 
---
Layout: SectionTitle
## One more thing...

---
Layout: Split
### Option 1

```
ds1 = [
  ['lat','lon','name','tz'],
  [51.51,0.13,'London',+0],
  [40.71,74.01,'New York',-5],
  [35.69,139.68,'Tokyo',+8]
]
```

+++
### Option 2
```
ds2 = {
  'lat':[51.51,40.71,35.69],
  'lon':[0.13,74.01,139.68],
  'tz':[+0,-5,+8],
  'name':['London','New York','Tokyo']
}
```
---
### Thinking it Through

Why does this work for both computers _and_ people?
```
ds2 = {
  'lat':[51.51,40.71,35.69],
  'lon':[0.13,74.01,139.68],
  'tz':[+0,-5,+8],
  'name':['London','New York','Tokyo']
}
```
^ This has advantages for the computer because everything of type 'lat' is a float, everything of type 'tz' is an integer, and everything of type 'name' is a string.

^ More subtly: we are doing away with the idea that the order of columns matters (humans don't care that a city's name is in the first column, and a city's latitude in the second). We just want to _find_ the column. But because we have a dictionary-of-lists we can ensure that the _row order_ is preserved. Let's see this in action.

---
### Examples
```
print(ds2['name'][0])
> London
print(ds2['lat'][0])
> 51.51
print(ds2['tz'][0])
> 0
```
So we know that everything in `ds2[<dictionary>][n]` is related to **the same n$$^{th}$$ city**,.

---
### How is _that_ easier???

Remember that we can use _any_ immutable 'thing' as a key. This means...
```
city = 'Tokyo'
city_idx = ds2['name'].index(city)
print(city_idx) # Prints 2
print("The time zone difference to " + city + " is " + str(
  ds2['tz'][city_idx]
)) # Prints 8
```
We can re-write this into a single line as:
```
city = 'London'
print("The time zone different to " + city + " is " + 
  str(ds2['tz'][ ds2['name'].index(city)] ))
```

^ This achieves several useful things:
^ 1. It is _fast_: faster than iterating over a list-of-lists or dictionary-of-dictionaries.
^ 2. All data in a list is _of the same type_ so we can easily add checks to make sure that it's valid.
^ 3. We can add more columns and the process of finding something _is just as fast_ as it is now. And adding more rows doesn't make it much slower either!
^ 4. Also, notice how in these two examples we don't try to write the second example in one go: first, we work it out as a set of steps: how do we figure out what 'row' (position in the list) Tokyo is in? Now that we've got that, how do we retrieve the time zone value for Tokyo? We know that code works, now let's do _variable substitution_, as we would if we were doing maths: we can replace the `city_idx` in the time zone lookup with `ds2['name'].index('Tokyo')`.

---
Layout: SectionTitle
## This is critical! 
### If you can get your head around it, then ![](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/microsoft/209/shocked-face-with-exploding-head_1f92f.png)
### because you are dealing with a data **structure**.

^ I have many years of experience and it took me several _hours_ to get my head around why this approach is _better_ as a way of working with data.

---
